{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import onnx\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bat_resnext26ts.ch_in1k', 'beit_base_patch16_224.in22k_ft_in22k', 'beit_base_patch16_224.in22k_ft_in22k_in1k', 'beit_base_patch16_384.in22k_ft_in22k_in1k', 'beit_large_patch16_224.in22k_ft_in22k']\n"
     ]
    }
   ],
   "source": [
    "! python -c \"from timm import list_models; print(list_models(pretrained=True)[:5])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1298\n"
     ]
    }
   ],
   "source": [
    "# 一共有1298个模型\n",
    "model_pretrain_list = timm.list_models(pretrained=True)\n",
    "print(len(model_pretrain_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['swin_base_patch4_window7_224',\n",
       " 'swin_base_patch4_window12_384',\n",
       " 'swin_large_patch4_window7_224',\n",
       " 'swin_large_patch4_window12_384',\n",
       " 'swin_s3_base_224',\n",
       " 'swin_s3_small_224',\n",
       " 'swin_s3_tiny_224',\n",
       " 'swin_small_patch4_window7_224',\n",
       " 'swin_tiny_patch4_window7_224',\n",
       " 'swinv2_base_window8_256',\n",
       " 'swinv2_base_window12_192',\n",
       " 'swinv2_base_window12to16_192to256',\n",
       " 'swinv2_base_window12to24_192to384',\n",
       " 'swinv2_base_window16_256',\n",
       " 'swinv2_cr_base_224',\n",
       " 'swinv2_cr_base_384',\n",
       " 'swinv2_cr_base_ns_224',\n",
       " 'swinv2_cr_giant_224',\n",
       " 'swinv2_cr_giant_384',\n",
       " 'swinv2_cr_huge_224',\n",
       " 'swinv2_cr_huge_384',\n",
       " 'swinv2_cr_large_224',\n",
       " 'swinv2_cr_large_384',\n",
       " 'swinv2_cr_small_224',\n",
       " 'swinv2_cr_small_384',\n",
       " 'swinv2_cr_small_ns_224',\n",
       " 'swinv2_cr_small_ns_256',\n",
       " 'swinv2_cr_tiny_224',\n",
       " 'swinv2_cr_tiny_384',\n",
       " 'swinv2_cr_tiny_ns_224',\n",
       " 'swinv2_large_window12_192',\n",
       " 'swinv2_large_window12to16_192to256',\n",
       " 'swinv2_large_window12to24_192to384',\n",
       " 'swinv2_small_window8_256',\n",
       " 'swinv2_small_window16_256',\n",
       " 'swinv2_tiny_window8_256',\n",
       " 'swinv2_tiny_window16_256']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看所有的swin-transformer模型\n",
    "all_densnet_models = timm.list_models(\"*swin*\")\n",
    "all_densnet_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载swin模型，并进行参数的配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth',\n",
       " 'file': '/mnt/share_disk/cdd/pretrained_models/swin_tiny_patch4_window7_224.pth',\n",
       " 'hf_hub_id': 'timm/swin_tiny_patch4_window7_224.ms_in1k',\n",
       " 'architecture': 'swin_tiny_patch4_window7_224',\n",
       " 'tag': 'ms_in1k',\n",
       " 'custom_load': False,\n",
       " 'input_size': (3, 224, 224),\n",
       " 'fixed_input_size': True,\n",
       " 'interpolation': 'bicubic',\n",
       " 'crop_pct': 0.9,\n",
       " 'crop_mode': 'center',\n",
       " 'mean': (0.485, 0.456, 0.406),\n",
       " 'std': (0.229, 0.224, 0.225),\n",
       " 'num_classes': 1000,\n",
       " 'pool_size': (7, 7),\n",
       " 'first_conv': 'patch_embed.proj',\n",
       " 'classifier': 'head.fc',\n",
       " 'license': 'mit'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = timm.create_model('swin_tiny_patch4_window7_224', num_classes=1000, pretrained=True, pretrained_cfg_overlay=dict(file='/mnt/share_disk/cdd/pretrained_models/swin_tiny_patch4_window7_224.pth'))\n",
    "model.default_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/timm/lib/python3.8/site-packages/torch/__init__.py:1493: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "model.eval()\n",
    "now = datetime.datetime.now()\n",
    "model_file_name = f\"/mnt/share_disk/cdd/export_onnx_models/swin_tiny_patch4_window7_224_{now.strftime('%Y%m%d_%H%M%S')}.onnx\"\n",
    "\n",
    "torch.onnx.export(model, dummy_input, model_file_name, opset_version=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onnx_simplify(path):\n",
    "    import onnx\n",
    "    from onnxsim import simplify\n",
    "    \n",
    "    # simplify the onnx model & load onnx model\n",
    "    onnx_model = onnx.load(path)  \n",
    "    model_simp, check = simplify(onnx_model)\n",
    "    assert check, \"Simplified ONNX model could not be validated\"\n",
    "    \n",
    "    output_path = path.split(\".\")[0] + \"_onnxsim.\" + path.split(\".\")[-1]\n",
    "    \n",
    "    onnx.save(model_simp, output_path)\n",
    "    \n",
    "    print(\"The simplified ONNX model is saved to {}\".format(output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "InferenceError",
     "evalue": "[ShapeInferenceError] (op_type:Transpose, node name: /layers/layers.0/blocks/blocks.0/Transpose_1): [ShapeInferenceError] Inferred shape and existing shape differ in rank: (6) vs (0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInferenceError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# onnxsim 简化会出问题，error\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43monnx_simplify\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/mnt/share_disk/cdd/pytorch-image-models/swin-transformer_new.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 7\u001b[0m, in \u001b[0;36monnx_simplify\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# simplify the onnx model & load onnx model\u001b[39;00m\n\u001b[1;32m      6\u001b[0m onnx_model \u001b[38;5;241m=\u001b[39m onnx\u001b[38;5;241m.\u001b[39mload(path)  \n\u001b[0;32m----> 7\u001b[0m model_simp, check \u001b[38;5;241m=\u001b[39m \u001b[43msimplify\u001b[49m\u001b[43m(\u001b[49m\u001b[43monnx_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m check, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimplified ONNX model could not be validated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m output_path \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_onnxsim.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/timm/lib/python3.8/site-packages/onnxsim/onnx_simplifier.py:199\u001b[0m, in \u001b[0;36msimplify\u001b[0;34m(model, check_n, perform_optimization, skip_fuse_bn, overwrite_input_shapes, test_input_shapes, skipped_optimizers, skip_constant_folding, skip_shape_inference, input_data, dynamic_input_shape, custom_lib, include_subgraph, unused_output, tensor_size_threshold, mutable_initializer, input_shapes)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     model_bytes \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mSerializeToString()\n\u001b[0;32m--> 199\u001b[0m     model_opt_bytes \u001b[38;5;241m=\u001b[39m \u001b[43mC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimplify\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_bytes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipped_optimizers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip_shape_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensor_size_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(model_opt_bytes) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimplified model larger than 2GB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mInferenceError\u001b[0m: [ShapeInferenceError] (op_type:Transpose, node name: /layers/layers.0/blocks/blocks.0/Transpose_1): [ShapeInferenceError] Inferred shape and existing shape differ in rank: (6) vs (0)"
     ]
    }
   ],
   "source": [
    "# onnxsim 简化会出问题，error\n",
    "onnx_simplify(\"/mnt/share_disk/cdd/pytorch-image-models/swin-transformer_new.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
